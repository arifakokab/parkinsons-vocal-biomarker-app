# -*- coding: utf-8 -*-
"""updatedstreamlitapp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wN-3amhp2Mv1enuO5CWlKegYuidUsN_M
"""

# app.py -- CarePath AI Foundation Parkinson's Vocal Biomarker Estimator
# Created by Arifa Kokab, M.Sc.Eng. Applied AI, University of San Diego

import streamlit as st
import numpy as np
import pandas as pd
import librosa
import joblib
import pickle
import os
from scipy.signal import hilbert
from scipy.stats import entropy
import tensorflow as tf
from tensorflow import keras
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from io import BytesIO
from datetime import datetime
import av
import soundfile as sf
import tempfile

from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode

# --- 1. TITLE & INTRO ---
st.set_page_config(page_title="Parkinson's Vocal Biomarker Estimator", layout="centered")

st.markdown("""
<h1 style='font-size:2.2rem; margin-bottom:0.5rem;'>Vocal Biomarker Estimator for Parkinson's Disease</h1>
<p style='font-size:1.0rem; color:#555; margin-top:0.2rem; margin-bottom:0.7rem;'>
Developed by <b>Arifa Kokab</b> as part of the <b>M.Sc.(Eng) Applied Artificial Intelligence</b> capstone project (University of San Diego, Shiley-Marcos School of Engineering) and launched by CarePath AI Foundation.<br>
This initiative provides <b>free, accessible, non-invasive screening and severity estimation</b> of Parkinson's Disease via voice, for public use.
</p>
""", unsafe_allow_html=True)
st.markdown("<hr style='margin-top:0.5rem; margin-bottom:1rem;'>", unsafe_allow_html=True)

# --- 2. Load Models and Tools ---
@st.cache_resource
def load_models():
    mlp = joblib.load("parkinsons_mlp_model.pkl")
    scaler_class = joblib.load("scaler.pkl")
    with open("feature_columns.pkl", "rb") as f:
        columns_class = pickle.load(f)
    lstmcnn = keras.models.load_model("best_lstmcnn_model.keras")
    scaler_sev = joblib.load("scaler_lstmcnn.pkl")
    with open("feature_columns_severity.pkl", "rb") as f:
        columns_sev = pickle.load(f)
    return mlp, scaler_class, columns_class, lstmcnn, scaler_sev, columns_sev

mlp, scaler_class, columns_class, lstmcnn, scaler_sev, columns_sev = load_models()

# --- 3. Usage Counter (in a local file) ---
def increment_counter():
    try:
        with open("usage_counter.txt", "r+") as f:
            count = int(f.read().strip()) + 1
            f.seek(0)
            f.write(str(count))
    except:
        with open("usage_counter.txt", "w") as f:
            count = 1
            f.write(str(count))
    return count

def get_counter():
    if os.path.exists("usage_counter.txt"):
        with open("usage_counter.txt", "r") as f:
            return int(f.read().strip())
    return 0

# --- 4. AUDIO RECORDING (Manual Save) ---
st.header("Step 1: Record Your Voice")
st.write("""
**Please say the sustained vowel "aaah" for at least 5 seconds.**
Ensure a quiet environment for the best results.
""")

if "audio_file" not in st.session_state:
    st.session_state.audio_file = None
if "audio_saved" not in st.session_state:
    st.session_state.audio_saved = False

# Recorder class
class AudioRecorder(AudioProcessorBase):
    def __init__(self):
        self.frames = []
    def recv(self, frame: av.AudioFrame):
        self.frames.append(frame.to_ndarray().flatten())
        return frame

# Start/stop widget (uses streamlit-webrtc built-in controls)
audio_ctx = webrtc_streamer(
    key="audio",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=1024,
    rtc_configuration={},
    media_stream_constraints={"audio": True, "video": False},
    audio_processor_factory=AudioRecorder,
)

if audio_ctx and audio_ctx.state.playing:
    st.info("Recording... When done, **STOP** recording from the widget below, then click 'Save Audio'.")

# Show a button to save after stopping recording
if audio_ctx and not audio_ctx.state.playing and hasattr(audio_ctx, "audio_processor"):
    if st.button("Save Audio"):
        frames = audio_ctx.audio_processor.frames
        if frames:
            all_audio = np.concatenate(frames)
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                sf.write(f, all_audio, 48000)
                st.session_state.audio_file = f.name
                st.session_state.audio_saved = True
            st.success("Audio saved! You can now run the analysis.")
        else:
            st.warning("No audio frames foundâ€”please record again.")

# Show playback button after saving audio
if st.session_state.audio_file:
    st.audio(st.session_state.audio_file)

# --- 5. FEATURE EXTRACTION FUNCTIONS ---
def extract_features(wav_file, feature_columns, sequence_length=5):
    y, sr = librosa.load(wav_file, sr=16000)
    try:
        f0, _, _ = librosa.pyin(y, fmin=80, fmax=400, sr=sr)
        f0_valid = f0[~np.isnan(f0)]
        jitter = np.std(f0_valid) / np.mean(f0_valid)
    except Exception:
        jitter = 0.0
    shimmer = np.std(librosa.amplitude_to_db(np.abs(librosa.stft(y))))
    hnr = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
    nhr = np.mean(np.abs(hilbert(y)))
    features = {
        'Jitter(%)': jitter,
        'Jitter(Abs)': np.abs(jitter),
        'Jitter:RAP': jitter/2,
        'Jitter:PPQ5': jitter/3,
        'Jitter:DDP': jitter/4,
        'Shimmer': shimmer,
        'Shimmer(dB)': shimmer / 10,
        'Shimmer:APQ3': shimmer/2,
        'Shimmer:APQ5': shimmer/3,
        'Shimmer:APQ11': shimmer/4,
        'Shimmer:DDA': shimmer/5,
        'NHR': nhr,
        'HNR': hnr
    }
    # RPDE
    def compute_rpde(y, sr):
        frames = librosa.util.frame(y, frame_length=sr//10, hop_length=sr//20)
        entropy_vals = [entropy(np.histogram(frame, bins=10)[0]+1) for frame in frames.T]
        return np.mean(entropy_vals)
    features['RPDE'] = compute_rpde(y, sr)
    # DFA
    def compute_dfa(y):
        N = len(y)
        x = np.cumsum(y - np.mean(y))
        scale = 1000
        dfa = np.std(x[:N//scale]) if N//scale > 0 else 0
        return dfa
    features['DFA'] = compute_dfa(y)
    # PPE
    def compute_ppe(y, sr):
        f0, _, _ = librosa.pyin(y, fmin=80, fmax=400, sr=sr)
        f0 = f0[~np.isnan(f0)]
        if len(f0) == 0:
            return 0.0
        hist, _ = np.histogram(f0, bins=10)
        hist = hist + 1
        return entropy(hist)
    features['PPE'] = compute_ppe(y, sr)
    fdf = pd.DataFrame([features])[feature_columns]
    return fdf

# --- 6. ANALYSIS PIPELINE ---
if st.button("Run Analysis", type="primary"):
    audio_file = st.session_state.audio_file  # Always get from session
    if not st.session_state.get("audio_saved", False) or not audio_file:
        st.warning("Please record your voice and click 'Save Audio' first.")
    else:
        try:
            X_class = extract_features(audio_file, columns_class)
            X_class_scaled = scaler_class.transform(X_class)
            pred_class = mlp.predict(X_class_scaled)[0]
            pred_label = "Parkinson's Disease Detected" if pred_class == 1 else "Healthy (No PD Detected)"
            if pred_class == 1:
                st.subheader("Parkinson's Disease Detected")
                st.write("Now estimating severity...")
                X_sev = extract_features(audio_file, columns_sev)
                X_sev_scaled = scaler_sev.transform(X_sev)
                X_sev_seq = np.tile(X_sev_scaled, (5,1)).reshape(1,5,len(columns_sev))
                pred_sev = lstmcnn.predict(X_sev_seq).flatten()[0]
                if pred_sev < 20:
                    severity = "Mild (UPDRS < 20)"
                elif pred_sev < 35:
                    severity = "Moderate (UPDRS 20-34)"
                elif pred_sev < 50:
                    severity = "Moderately Severe (UPDRS 35-49)"
                else:
                    severity = "Severe (UPDRS 50+)"
                st.success(f"Predicted Disease Severity: **{severity}** (Estimated UPDRS: {pred_sev:.1f})")
            else:
                st.success("Result: Healthy. No evidence of Parkinson's Disease was detected.")
                severity = "Not Applicable"
                pred_sev = None
            # --- PDF Download ---
            buffer = BytesIO()
            c = canvas.Canvas(buffer, pagesize=letter)
            c.setFont("Helvetica", 18)
            c.drawString(30, 760, "CarePath AI Foundation")
            c.setFont("Helvetica", 14)
            c.drawString(30, 735, "Parkinson's Vocal Biomarker Screening Report")
            c.setFont("Helvetica", 10)
            c.drawString(30, 710, f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            c.drawString(30, 695, f"Screening Outcome: {pred_label}")
            if pred_label == "Parkinson's Disease Detected":
                c.drawString(30, 680, f"Estimated Severity: {severity} (UPDRS: {pred_sev:.1f})")
            else:
                c.drawString(30, 680, f"Estimated Severity: {severity}")
            c.drawString(30, 655, "NOTE: This is an AI-based non-clinical screening tool. Results are for informational")
            c.drawString(30, 643, "purposes only and should not be considered a medical diagnosis.")
            c.drawString(30, 630, "Please consult a neurologist for a full evaluation if you have concerns.")
            c.save()
            buffer.seek(0)
            st.download_button(
                label="Download PDF Report",
                data=buffer,
                file_name="CarePathAI_Parkinsons_Screening_Report.pdf",
                mime="application/pdf"
            )
            counter = increment_counter()
            st.info(f"This app has been used {counter} times.")
        except Exception as e:
            st.error(f"An error occurred: {e}")

# --- 7. DISCLAIMERS AND FOOTER ---
st.markdown("""
---
**Disclaimer:**
This application is for informational and research purposes only. It is **not** a substitute for professional medical evaluation. Always consult with a qualified healthcare provider for any concerns about Parkinsonâ€™s Disease or other medical conditions.

**App usage data is anonymous and never shared.**

---

**Â© 2025 CarePath AI Foundation & Arifa Kokab**
""")
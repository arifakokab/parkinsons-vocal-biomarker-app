# -*- coding: utf-8 -*-
"""updatedstreamlitapp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wN-3amhp2Mv1enuO5CWlKegYuidUsN_M
"""

# app.py -- CarePath AI Foundation Parkinson's Vocal Biomarker Estimator
# Created by Arifa Kokab, M.Sc.Eng. Applied AI, University of San Diego

import streamlit as st
import numpy as np
import pandas as pd
import librosa
import joblib
import pickle
import os
from scipy.signal import hilbert
from scipy.stats import entropy
import tensorflow as tf
from tensorflow import keras
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from io import BytesIO
from datetime import datetime
import av
import soundfile as sf
import tempfile

from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode

# --- 1. TITLE & INTRO ---
st.set_page_config(page_title="Parkinson's Vocal Biomarker Estimator", layout="centered")
st.title("Vocal Biomarker Estimator for Parkinson's Disease")
st.markdown("""
**Developed by Arifa Kokab as part of the M.Sc.(Eng) Applied Artificial Intelligence capstone project at the University of San Diego (Shiley-Marcos School of Engineering) and launched by CarePath AI Foundation.
This initiative provides free, accessible, non-invasive screening and severity estimation of Parkinson's Disease via voice, for public and clinical use.**
---
""")

# --- 2. Load Models and Tools ---
@st.cache_resource
def load_models():
    mlp = joblib.load("parkinsons_mlp_model.pkl")
    scaler_class = joblib.load("scaler.pkl")
    with open("feature_columns.pkl", "rb") as f:
        columns_class = pickle.load(f)
    lstmcnn = keras.models.load_model("best_lstmcnn_model.keras")
    scaler_sev = joblib.load("scaler_lstmcnn.pkl")
    with open("feature_columns_severity.pkl", "rb") as f:
        columns_sev = pickle.load(f)
    return mlp, scaler_class, columns_class, lstmcnn, scaler_sev, columns_sev

mlp, scaler_class, columns_class, lstmcnn, scaler_sev, columns_sev = load_models()

# --- 3. Usage Counter (in a local file) ---
def increment_counter():
    try:
        with open("usage_counter.txt", "r+") as f:
            count = int(f.read().strip()) + 1
            f.seek(0)
            f.write(str(count))
    except:
        with open("usage_counter.txt", "w") as f:
            count = 1
            f.write(str(count))
    return count

def get_counter():
    if os.path.exists("usage_counter.txt"):
        with open("usage_counter.txt", "r") as f:
            return int(f.read().strip())
    return 0

# --- 4. AUDIO RECORDING ---
st.header("Step 1: Record Your Voice")
st.write("""
**Please say the sustained vowel "aaah" for at least 5 seconds.**
Ensure a quiet environment for the best results.
""")

class AudioRecorder(AudioProcessorBase):
    def __init__(self):
        self.frames = []
    def recv(self, frame: av.AudioFrame):
        self.frames.append(frame.to_ndarray().flatten())
        return frame

audio_ctx = webrtc_streamer(
    key="sendonly-audio",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=1024,
    client_settings={"mediaStreamConstraints": {"audio": True, "video": False}},
    desired_playing_state=True,
    audio_processor_factory=AudioRecorder,
)

audio_bytes = None

if audio_ctx.state.playing and hasattr(audio_ctx, "audio_processor") and audio_ctx.audio_processor is not None:
    if st.button("Stop & Save Audio"):
        all_audio = np.concatenate(audio_ctx.audio_processor.frames).flatten()
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            sf.write(f, all_audio, 16000)
            audio_bytes = f.name
        # Clear buffer after saving so new recordings start fresh
        audio_ctx.audio_processor.frames = []
        st.success("Audio saved! You can now run the analysis.")
        st.session_state["audio_saved"] = True
elif "audio_saved" not in st.session_state:
    st.session_state["audio_saved"] = False

# --- 5. FEATURE EXTRACTION FUNCTIONS ---
def extract_features(wav_file, feature_columns, sequence_length=5):
    y, sr = librosa.load(wav_file, sr=16000)
    try:
        f0, _, _ = librosa.pyin(y, fmin=80, fmax=400, sr=sr)
        f0_valid = f0[~np.isnan(f0)]
        jitter = np.std(f0_valid) / np.mean(f0_valid)
    except Exception:
        jitter = 0.0
    shimmer = np.std(librosa.amplitude_to_db(np.abs(librosa.stft(y))))
    hnr = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
    nhr = np.mean(np.abs(hilbert(y)))
    features = {
        'Jitter(%)': jitter,
        'Jitter(Abs)': np.abs(jitter),
        'Jitter:RAP': jitter/2,
        'Jitter:PPQ5': jitter/3,
        'Jitter:DDP': jitter/4,
        'Shimmer': shimmer,
        'Shimmer(dB)': shimmer / 10,
        'Shimmer:APQ3': shimmer/2,
        'Shimmer:APQ5': shimmer/3,
        'Shimmer:APQ11': shimmer/4,
        'Shimmer:DDA': shimmer/5,
        'NHR': nhr,
        'HNR': hnr
    }
    # RPDE
    def compute_rpde(y, sr):
        frames = librosa.util.frame(y, frame_length=sr//10, hop_length=sr//20)
        entropy_vals = [entropy(np.histogram(frame, bins=10)[0]+1) for frame in frames.T]
        return np.mean(entropy_vals)
    features['RPDE'] = compute_rpde(y, sr)
    # DFA
    def compute_dfa(y):
        N = len(y)
        x = np.cumsum(y - np.mean(y))
        scale = 1000
        dfa = np.std(x[:N//scale]) if N//scale > 0 else 0
        return dfa
    features['DFA'] = compute_dfa(y)
    # PPE
    def compute_ppe(y, sr):
        f0, _, _ = librosa.pyin(y, fmin=80, fmax=400, sr=sr)
        f0 = f0[~np.isnan(f0)]
        if len(f0) == 0:
            return 0.0
        hist, _ = np.histogram(f0, bins=10)
        hist = hist + 1
        return entropy(hist)
    features['PPE'] = compute_ppe(y, sr)
    fdf = pd.DataFrame([features])[feature_columns]
    return fdf

# --- 6. ANALYSIS PIPELINE ---
if st.button("Run Analysis", type="primary"):
    if not st.session_state.get("audio_saved", False) or audio_bytes is None:
        st.warning("Please record your voice and click 'Stop & Save Audio' first.")
    else:
        try:
            X_class = extract_features(audio_bytes, columns_class)
            X_class_scaled = scaler_class.transform(X_class)
            pred_class = mlp.predict(X_class_scaled)[0]
            pred_label = "Parkinson's Disease Detected" if pred_class == 1 else "Healthy (No PD Detected)"
            if pred_class == 1:
                st.subheader("Parkinson's Disease Detected")
                st.write("Now estimating severity...")
                X_sev = extract_features(audio_bytes, columns_sev)
                X_sev_scaled = scaler_sev.transform(X_sev)
                X_sev_seq = np.tile(X_sev_scaled, (5,1)).reshape(1,5,len(columns_sev))
                pred_sev = lstmcnn.predict(X_sev_seq).flatten()[0]
                if pred_sev < 20:
                    severity = "Mild (UPDRS < 20)"
                elif pred_sev < 35:
                    severity = "Moderate (UPDRS 20-34)"
                elif pred_sev < 50:
                    severity = "Moderately Severe (UPDRS 35-49)"
                else:
                    severity = "Severe (UPDRS 50+)"
                st.success(f"Predicted Disease Severity: **{severity}** (Estimated UPDRS: {pred_sev:.1f})")
            else:
                st.success("Result: Healthy. No evidence of Parkinson's Disease was detected.")
                severity = "Not Applicable"
                pred_sev = None
            # --- PDF Download ---
            buffer = BytesIO()
            c = canvas.Canvas(buffer, pagesize=letter)
            c.setFont("Helvetica", 18)
            c.drawString(30, 760, "CarePath AI Foundation")
            c.setFont("Helvetica", 14)
            c.drawString(30, 735, "Parkinson's Vocal Biomarker Screening Report")
            c.setFont("Helvetica", 10)
            c.drawString(30, 710, f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            c.drawString(30, 695, f"Screening Outcome: {pred_label}")
            if pred_label == "Parkinson's Disease Detected":
                c.drawString(30, 680, f"Estimated Severity: {severity} (UPDRS: {pred_sev:.1f})")
            else:
                c.drawString(30, 680, f"Estimated Severity: {severity}")
            c.drawString(30, 655, "NOTE: This is an AI-based non-clinical screening tool. Results are for informational")
            c.drawString(30, 643, "purposes only and should not be considered a medical diagnosis.")
            c.drawString(30, 630, "Please consult a neurologist for a full evaluation if you have concerns.")
            c.save()
            buffer.seek(0)
            st.download_button(
                label="Download PDF Report",
                data=buffer,
                file_name="CarePathAI_Parkinsons_Screening_Report.pdf",
                mime="application/pdf"
            )
            counter = increment_counter()
            st.info(f"This app has been used {counter} times.")
        except Exception as e:
            st.error(f"An error occurred: {e}")

# --- 7. DISCLAIMERS AND FOOTER ---
st.markdown("""
---
**Disclaimer:**
This application is for informational and research purposes only. It is **not** a substitute for professional medical evaluation. Always consult with a qualified healthcare provider for any concerns about Parkinson’s Disease or other medical conditions.

**App usage data is anonymous and never shared.**

---

**© 2025 CarePath AI Foundation & Arifa Kokab**
""")
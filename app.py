# -*- coding: utf-8 -*-
"""Parkinson'sStreamlitApp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kZU0E5ok9ezNk9ilZMY_0kX5JU4gX7FH
"""

# app.py -- CarePath AI Foundation Parkinson's Vocal Biomarker Estimator
# Created by Arifa Kokab, M.Sc.Eng. Applied AI, University of San Diego

import streamlit as st
import numpy as np
import pandas as pd
import librosa
import joblib
import pickle
import os
from scipy.signal import hilbert
from scipy.stats import entropy
import tensorflow as tf
from tensorflow import keras
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from io import BytesIO
from datetime import datetime

# For browser audio recording
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode

# --- 1. TITLE & INTRO ---
st.set_page_config(page_title="Parkinson's Vocal Biomarker Estimator", layout="centered")
st.title("Vocal Biomarker Estimator for Parkinson's Disease")
st.markdown("""
**Developed by Arifa Kokab as part of the M.Sc.(Eng) Applied Artificial Intelligence capstone project at the University of San Diego (Shiley-Marcos School of Engineering) and launched by CarePath AI Foundation.
This initiative provides free, accessible, non-invasive screening and severity estimation of Parkinson's Disease via voice, for public and clinical use.**

---
""")

# --- 2. Load Models and Tools ---
@st.cache_resource
def load_models():
    mlp = joblib.load("parkinsons_mlp_model.pkl")
    scaler_class = joblib.load("scaler.pkl")
    with open("feature_columns.pkl", "rb") as f:
        columns_class = pickle.load(f)
    lstmcnn = keras.models.load_model("best_lstmcnn_model_tf216.keras")
    scaler_sev = joblib.load("scaler_lstmcnn.pkl")
    with open("feature_columns_severity.pkl", "rb") as f:
        columns_sev = pickle.load(f)
    return mlp, scaler_class, columns_class, lstmcnn, scaler_sev, columns_sev

mlp, scaler_class, columns_class, lstmcnn, scaler_sev, columns_sev = load_models()

# --- 3. Usage Counter (in a local file) ---
def increment_counter():
    try:
        with open("usage_counter.txt", "r+") as f:
            count = int(f.read().strip()) + 1
            f.seek(0)
            f.write(str(count))
    except:
        with open("usage_counter.txt", "w") as f:
            count = 1
            f.write(str(count))
    return count

def get_counter():
    if os.path.exists("usage_counter.txt"):
        with open("usage_counter.txt", "r") as f:
            return int(f.read().strip())
    return 0

# --- 4. AUDIO RECORDING ---
st.header("Step 1: Record Your Voice")
st.write("""
**Please say the sustained vowel "aaah" for at least 5 seconds.**
Ensure a quiet environment for the best results.
""")

audio_bytes = None
result = webrtc_streamer(
    key="speech",
    mode=WebRtcMode.SENDRECV,
    audio_receiver_size=256,
    client_settings={"mediaStreamConstraints": {"audio": True, "video": False}}
)
if result.audio_receiver:
    audio_frames = []
    while True:
        try:
            audio_frame = result.audio_receiver.get_frame(timeout=1)
            audio_frames.append(audio_frame.to_ndarray())
        except Exception:
            break
    if audio_frames:
        audio_np = np.concatenate(audio_frames, axis=0)
        sr = 48000
        # Save to temp wav for librosa
        import soundfile as sf
        sf.write("temp_input.wav", audio_np, sr)
        audio_bytes = "temp_input.wav"

# --- 5. FEATURE EXTRACTION FUNCTIONS (Clinical-grade) ---
def extract_features(wav_file, feature_columns, sequence_length=5):
    """
    Extract all required features (including RPDE, DFA, PPE) for the models.
    Returns a DataFrame with columns as in feature_columns.
    """
    y, sr = librosa.load(wav_file, sr=16000)
    # --- Simple features ---
    jitter = np.std(librosa.pyin(y, fmin=80, fmax=400, sr=sr)[0]) / np.mean(librosa.pyin(y, fmin=80, fmax=400, sr=sr)[0])
    shimmer = np.std(librosa.amplitude_to_db(np.abs(librosa.stft(y))))
    hnr = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
    nhr = np.mean(np.abs(hilbert(y)))
    # Simpler versions for demo; for real use, implement classic definitions or use Praat
    features = {
        'Jitter(%)': jitter,
        'Jitter(Abs)': np.abs(jitter),
        'Jitter:RAP': jitter/2,
        'Jitter:PPQ5': jitter/3,
        'Jitter:DDP': jitter/4,
        'Shimmer': shimmer,
        'Shimmer(dB)': shimmer / 10,
        'Shimmer:APQ3': shimmer/2,
        'Shimmer:APQ5': shimmer/3,
        'Shimmer:APQ11': shimmer/4,
        'Shimmer:DDA': shimmer/5,
        'NHR': nhr,
        'HNR': hnr
    }

    # --- RPDE ---
    def compute_rpde(y, sr):
        # Recurrence plot entropy as a measure of dynamical complexity (approx.)
        frames = librosa.util.frame(y, frame_length=sr//10, hop_length=sr//20)
        entropy_vals = [entropy(np.histogram(frame, bins=10)[0]+1) for frame in frames.T]
        return np.mean(entropy_vals)
    features['RPDE'] = compute_rpde(y, sr)

    # --- DFA ---
    def compute_dfa(y):
        # Simplified DFA: Use standard deviation of local detrended signals
        N = len(y)
        x = np.cumsum(y - np.mean(y))
        scale = 1000
        dfa = np.std(x[:N//scale])
        return dfa
    features['DFA'] = compute_dfa(y)

    # --- PPE ---
    def compute_ppe(y, sr):
        # Pitch Period Entropy (approx.)
        f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=80, fmax=400, sr=sr)
        f0 = f0[~np.isnan(f0)]
        hist, _ = np.histogram(f0, bins=10)
        hist = hist + 1
        return entropy(hist)
    features['PPE'] = compute_ppe(y, sr)

    # --- Repackage for each model ---
    fdf = pd.DataFrame([features])[feature_columns]
    return fdf

# --- 6. CLASSIFICATION AND SEVERITY ESTIMATION PIPELINE ---
if st.button("Run Analysis", type="primary"):
    if not audio_bytes:
        st.warning("Please record your voice first.")
    else:
        # 1. Extract Features for Classification
        X_class = extract_features(audio_bytes, columns_class)
        X_class_scaled = scaler_class.transform(X_class)
        pred_class = mlp.predict(X_class_scaled)[0]
        pred_label = "Parkinson's Disease Detected" if pred_class == 1 else "Healthy (No PD Detected)"

        # 2. If PD positive, estimate severity using LSTM-CNN
        if pred_class == 1:
            st.subheader("Parkinson's Disease Detected")
            st.write("Now estimating severity...")
            X_sev = extract_features(audio_bytes, columns_sev)
            X_sev_scaled = scaler_sev.transform(X_sev)
            # For LSTM, need shape: (batch, timesteps, features) -- replicate for window
            X_sev_seq = np.tile(X_sev_scaled, (5,1)).reshape(1,5,len(columns_sev))
            pred_sev = lstmcnn.predict(X_sev_seq).flatten()[0]
            # Output as severity range (e.g., "mild", "moderate", "severe")
            if pred_sev < 20:
                severity = "Mild (UPDRS < 20)"
            elif pred_sev < 35:
                severity = "Moderate (UPDRS 20-34)"
            elif pred_sev < 50:
                severity = "Moderately Severe (UPDRS 35-49)"
            else:
                severity = "Severe (UPDRS 50+)"
            st.success(f"Predicted Disease Severity: **{severity}** (Estimated UPDRS: {pred_sev:.1f})")
        else:
            st.success("Result: Healthy. No evidence of Parkinson's Disease was detected.")
            severity = "Not Applicable"
            pred_sev = None

        # --- PDF Download ---
        buffer = BytesIO()
        c = canvas.Canvas(buffer, pagesize=letter)
        c.setFont("Helvetica", 18)
        c.drawString(30, 760, "CarePath AI Foundation")
        c.setFont("Helvetica", 14)
        c.drawString(30, 735, "Parkinson's Vocal Biomarker Screening Report")
        c.setFont("Helvetica", 10)
        c.drawString(30, 710, f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        c.drawString(30, 695, f"Screening Outcome: {pred_label}")
        if pred_label == "Parkinson's Disease Detected":
            c.drawString(30, 680, f"Estimated Severity: {severity} (UPDRS: {pred_sev:.1f})")
        else:
            c.drawString(30, 680, f"Estimated Severity: {severity}")
        c.drawString(30, 655, "NOTE: This is an AI-based non-clinical screening tool. Results are for informational")
        c.drawString(30, 643, "purposes only and should not be considered a medical diagnosis.")
        c.drawString(30, 630, "Please consult a neurologist for a full evaluation if you have concerns.")
        c.save()
        buffer.seek(0)
        st.download_button(
            label="Download PDF Report",
            data=buffer,
            file_name="CarePathAI_Parkinsons_Screening_Report.pdf",
            mime="application/pdf"
        )

        # Increment and display usage counter
        counter = increment_counter()
        st.info(f"This app has been used {counter} times.")

# --- 7. DISCLAIMERS AND FOOTER ---
st.markdown("""
---
**Disclaimer:**
This application is for informational and research purposes only. It is **not** a substitute for professional medical evaluation. Always consult with a qualified healthcare provider for any concerns about Parkinson’s Disease or other medical conditions.

**App usage data is anonymous and never shared.**

---

**© 2025 CarePath AI Foundation & Arifa Kokab**
""")
